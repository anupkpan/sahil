import { VercelRequest, VercelResponse } from '@vercel/node';
import { OpenAI } from 'openai';

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

let cachedShayaris: { text: string; mood?: string; theme?: string }[] = [];

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Only POST requests allowed' });
  }

  const { mood, theme, depth } = req.body;

  // ‚è≥ Scrape only if cache is empty
  if (cachedShayaris.length === 0) {
    console.log('‚è≥ Running scraper inside handler...');
    const { scrapeShayarisFromBlog } = await import('../src/eknazariyaScraper');
    try {
      cachedShayaris = await scrapeShayarisFromBlog();
      console.log(`‚úÖ Scraped ${cachedShayaris.length} shayaris`);
    } catch (err) {
      console.error('‚ùå Scraping failed:', err);
    }
  }

  const match = cachedShayaris.find(
    (s) =>
      (s.mood || '').includes(mood) &&
      (s.theme || '').includes(theme)
  );

  if (match) {
    console.log(`üì¶ Returning shayari from cache`);
    return res.status(200).json({ response: match.text, source: 'eknazariya' });
  }

  const prompt = `‡§è‡§ï ${mood || '‡§≠‡§æ‡§µ‡•Å‡§ï'} ‡§î‡§∞ ${theme || '‡§™‡•ç‡§∞‡•á‡§Æ'} ‡§µ‡§ø‡§∑‡§Ø ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ${
    depth > 7 ? '‡§ó‡§π‡§∞‡•Ä' : '‡§∏‡§∞‡§≤'
  } ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§¨‡§§‡§æ‡§ì‡•§`;

  try {
    const result = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        { role: 'system', content: '‡§§‡•Å‡§Æ ‡§è‡§ï ‡§≠‡§æ‡§µ‡•Å‡§ï ‡§â‡§∞‡•ç‡§¶‡•Ç-‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§æ‡§Ø‡§∞ ‡§π‡•ã‡•§ ‡§ï‡•á‡§µ‡§≤ ‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§¶‡•ã‡•§' },
        { role: 'user', content: prompt },
      ],
    });

    const text = result.choices[0].message.content || '';

    return res.status(200).json({
      response: text.trim(),
      source: 'openai',
    });
  } catch (err: any) {
    return res.status(500).json({ error: 'OpenAI error', source: 'none' });
  }
}
