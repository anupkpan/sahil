import { VercelRequest, VercelResponse } from "@vercel/node";
import { OpenAI } from "openai";
import { loadCachedShayaris } from "./lib/eknazariyaScraper.js"; // <- .js important!

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });
let shayariCache: any[] = [];

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "Only POST requests allowed" });
  }

  const { mood = "", theme = "", depth = 5 } = req.body;

  try {
    if (shayariCache.length === 0) {
      console.log("üîÑ Preloading shayari from eknazariya...");
      shayariCache = await loadCachedShayaris();
      console.log(`‚úÖ Cached ${shayariCache.length} shayaris`);
    }

    const matches = shayariCache.filter(
      (s) => s.mood?.includes(mood) && s.theme?.includes(theme)
    );

    if (matches.length > 0) {
      const selected = matches[Math.floor(Math.random() * matches.length)];
      return res.status(200).json({
        lines: selected.lines,
        source: "eknazariya.com"
      });
    }

    // fallback to OpenAI
    const prompt = `‡§è‡§ï ${mood || "‡§≠‡§æ‡§µ‡•Å‡§ï"} ‡§î‡§∞ ${theme || "‡§™‡•ç‡§∞‡•á‡§Æ"} ‡§µ‡§ø‡§∑‡§Ø ‡§™‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ${depth > 7 ? "‡§ó‡§π‡§∞‡•Ä" : "‡§∏‡§∞‡§≤"} ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§¨‡§§‡§æ‡§ì‡•§`;

    const result = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: "‡§§‡•Å‡§Æ ‡§è‡§ï ‡§≠‡§æ‡§µ‡•Å‡§ï ‡§â‡§∞‡•ç‡§¶‡•Ç-‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§∂‡§æ‡§Ø‡§∞ ‡§π‡•ã‡•§ ‡§ï‡•á‡§µ‡§≤ ‡§∂‡§æ‡§Ø‡§∞‡•Ä ‡§¶‡•ã‡•§" },
        { role: "user", content: prompt }
      ]
    });

    const text = result.choices[0]?.message?.content || "";
    const lines = text.split("\n").map(line => line.trim()).filter(Boolean);

    return res.status(200).json({ lines, source: "OpenAI" });
  } catch (err: any) {
    console.error("‚ùå Error in handler", err);
    return res.status(500).json({ error: err.message || "Failed to generate shayari." });
  }
}
