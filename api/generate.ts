import { VercelRequest, VercelResponse } from "@vercel/node";
import { OpenAI } from "openai";
import { loadCachedShayaris } from "./lib/eknazariyaScraper.js"; // Use `.js` for Vercel compatibility

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

let shayariCache: any[] = [];

export default async function handler(req: VercelRequest, res: VercelResponse) {
  if (req.method !== "POST") {
    return res.status(405).json({ error: "Only POST requests allowed" });
  }

  const { mood = "", theme = "", depth = 5 } = req.body;

  // Cold start cache
  if (shayariCache.length === 0) {
    try {
      console.log("ğŸ”„ Preloading shayari from eknazariya...");
      shayariCache = await loadCachedShayaris();
      console.log(`âœ… Cached ${shayariCache.length} shayaris`);
      console.log("ğŸ“¦ Example cache entry:", shayariCache[0]);
    } catch (err) {
      console.error("âŒ Failed to load shayari cache", err);
    }
  }

  // Tokenize input for flexible matching
  const tokens = (mood + " " + theme).toLowerCase().split(/\s+/).filter(Boolean);

  // Match against shayari content directly
  const matches = shayariCache.filter((entry) => {
    const fullText = Array.isArray(entry.lines)
      ? entry.lines.join(" ").toLowerCase()
      : typeof entry === "string"
      ? entry.toLowerCase()
      : "";

    return tokens.some((token) => fullText.includes(token));
  });

  console.log("ğŸ” Matching for:", mood, theme);
  console.log("ğŸ“¦ Total cached:", shayariCache.length);
  console.log("ğŸ” Matched from cache:", matches.length);

  if (matches.length > 0) {
    const lines = matches[Math.floor(Math.random() * matches.length)].lines;
    return res.status(200).json({ lines, source: "eknazariya.com" });
  }

  // Fallback to OpenAI
  const prompt = `à¤à¤• ${mood || "à¤­à¤¾à¤µà¥à¤•"} à¤”à¤° ${theme || "à¤ªà¥à¤°à¥‡à¤®"} à¤µà¤¿à¤·à¤¯ à¤ªà¤° à¤†à¤§à¤¾à¤°à¤¿à¤¤ ${
    depth > 7 ? "à¤—à¤¹à¤°à¥€" : "à¤¸à¤°à¤²"
  } à¤¹à¤¿à¤‚à¤¦à¥€ à¤¶à¤¾à¤¯à¤°à¥€ à¤¬à¤¤à¤¾à¤“à¥¤`;

  try {
    const result = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        { role: "system", content: "à¤¤à¥à¤® à¤à¤• à¤­à¤¾à¤µà¥à¤• à¤‰à¤°à¥à¤¦à¥‚-à¤¹à¤¿à¤‚à¤¦à¥€ à¤¶à¤¾à¤¯à¤° à¤¹à¥‹à¥¤ à¤•à¥‡à¤µà¤² à¤¶à¤¾à¤¯à¤°à¥€ à¤¦à¥‹à¥¤" },
        { role: "user", content: prompt },
      ],
    });

    const text = result.choices[0].message.content || "";
    const lines = text
      .split("\n")
      .map((line) => line.trim())
      .filter((line) => line.length > 0);

    return res.status(200).json({ lines, source: "OpenAI" });
  } catch (err: any) {
    console.error("âŒ OpenAI error", err);
    return res.status(500).json({ error: err.message || "Failed to generate shayari." });
  }
}
